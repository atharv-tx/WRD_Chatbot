import streamlit as st
import json
import os
import requests

# ‚úÖ SAFE pdfplumber fallback
try:
    import pdfplumber
except:
    pdfplumber = None

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# -------------------------
# üåê LANGUAGE CONFIG
# -------------------------

LANGUAGES = {
    "‡§π‡§ø‡§Ç‡§¶‡•Ä": {
        "title": "üíß ‡§ú‡§≤ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§µ‡§ø‡§≠‡§æ‡§ó ‡§õ‡§§‡•ç‡§§‡•Ä‡§∏‡§ó‡§¢‡§º ‚Äì ‡§è‡§Ü‡§à ‡§ö‡•à‡§ü‡§¨‡•â‡§ü",
        "desc": "‡§Ø‡§π chatbot WRD ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º‡•ã‡§Ç ‡§î‡§∞ ‡§Ü‡§™‡§ï‡•á PDF ‡§∏‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§",
        "query": "‚úçÔ∏è ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≤‡§ø‡§ñ‡§ø‡§è",
        "button": "‚úÖ ‡§â‡§§‡•ç‡§§‡§∞ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç",
        "search": "üîé ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ñ‡•ã‡§ú‡•Ä ‡§ú‡§æ ‡§∞‡§π‡•Ä ‡§π‡•à...",
        "thinking": "ü§ñ ‡§â‡§§‡•ç‡§§‡§∞ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...",
        "answer": "ü§ñ ‡§ö‡•à‡§ü‡§¨‡•â‡§ü ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞:",
        "pdf": "üìÑ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§ø‡§è ‡§ó‡§è WRD PDF ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º:",
        "download": "‚¨áÔ∏è PDF ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "upload": "‚ûï ‡§Ö‡§™‡§®‡§æ PDF ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç (‡§µ‡•à‡§ï‡§≤‡•ç‡§™‡§ø‡§ï)",
        "pdf_override": "‚úÖ ‡§â‡§§‡•ç‡§§‡§∞ ‡§Ü‡§™‡§ï‡•á ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§ø‡§è ‡§ó‡§è PDF ‡§∏‡•á ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§",
        "info": "‚ÑπÔ∏è ‡§Ø‡§π ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§ï‡•á‡§µ‡§≤ ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§® ‡§π‡•á‡§§‡•Å ‡§π‡•à‡•§"
    },
    "English": {
        "title": "üíß WRD Chhattisgarh ‚Äì AI Chatbot",
        "desc": "This chatbot answers from WRD documents and your uploaded PDF.",
        "query": "‚úçÔ∏è Enter your question",
        "button": "‚úÖ Get Answer",
        "search": "üîé Searching information...",
        "thinking": "ü§ñ Generating answer...",
        "answer": "ü§ñ Chatbot Answer:",
        "pdf": "üìÑ Used WRD PDF Documents:",
        "download": "‚¨áÔ∏è Download PDF",
        "upload": "‚ûï Upload your own PDF (optional)",
        "pdf_override": "‚úÖ Answer is generated from your uploaded PDF.",
        "info": "‚ÑπÔ∏è This system is for guidance only."
    },
    "Hinglish": {
        "title": "üíß WRD Chhattisgarh ‚Äì AI Chatbot",
        "desc": "Ye chatbot WRD docs aur aapke PDF se answer deta hai.",
        "query": "‚úçÔ∏è Apna sawaal likhiye",
        "button": "‚úÖ Answer Pao",
        "search": "üîé Info dhoondi ja rahi hai...",
        "thinking": "ü§ñ Answer banaya ja raha hai...",
        "answer": "ü§ñ Chatbot Answer:",
        "pdf": "üìÑ Use hue WRD PDF:",
        "download": "‚¨áÔ∏è PDF Download",
        "upload": "‚ûï Apna PDF upload karein",
        "pdf_override": "‚úÖ Answer uploaded PDF se diya gaya hai.",
        "info": "‚ÑπÔ∏è Ye system sirf guidance ke liye hai."
    }
}


# -------------------------
# 1. Load WRD Knowledge Base
# -------------------------

@st.cache_resource
def load_kb_and_vectorizer():
    with open("wrd_kb.json", "r", encoding="utf-8") as f:
        docs = json.load(f)

    texts = []
    meta = []

    for d in docs:
        combined = f"{d.get('title', '')}\n\n{d.get('text', '')}"
        texts.append(combined)
        meta.append({
            "title": d.get("title", ""),
            "url": d.get("url", ""),
            "type": d.get("type", "")
        })

    vectorizer = TfidfVectorizer()
    doc_matrix = vectorizer.fit_transform(texts)

    return docs, meta, vectorizer, doc_matrix


def retrieve_context(query, vectorizer, doc_matrix, docs, meta, top_k=3):
    query_vec = vectorizer.transform([query])
    sims = cosine_similarity(query_vec, doc_matrix)[0]
    top_idx = sims.argsort()[::-1][:top_k]

    chunks = []
    pdf_sources = []

    for idx in top_idx:
        chunks.append(docs[idx]["text"][:900])
        if meta[idx]["type"].lower() == "pdf":
            pdf_sources.append(meta[idx])

    return "\n\n----\n\n".join(chunks), pdf_sources


# -------------------------
# 2. PDF READER
# -------------------------

def read_uploaded_pdf(uploaded_file):
    if pdfplumber is None:
        return "PDF reading not supported on this server."

    full_text = ""
    with pdfplumber.open(uploaded_file) as pdf:
        for p in pdf.pages:
            t = p.extract_text()
            if t:
                full_text += t + "\n"
    return full_text[:4000]


# -------------------------
# 3. CLOUD LLM (GROQ)
# -------------------------

def ask_llm_cloud(query, context, selected_lang):
    GROQ_API_KEY = st.secrets["GROQ_API_KEY"]

    prompt = f"""
You are a government information assistant.

Answer in this language: {selected_lang}
Use ONLY the given context.
Give a long, detailed, step-by-step answer.

Context:
{context}

Question:
{query}
"""

    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": "llama3-70b-8192",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.2
    }

    response = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers=headers,
        json=payload,
        timeout=60
    )

    return response.json()["choices"][0]["message"]["content"]


# -------------------------
# 4. STREAMLIT UI
# -------------------------

st.set_page_config(page_title="WRD AI Chatbot", layout="centered")

selected_lang = st.selectbox("üåê Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç", list(LANGUAGES.keys()))
ui = LANGUAGES[selected_lang]

st.title(ui["title"])
st.markdown(ui["desc"])

uploaded_pdf = st.file_uploader(ui["upload"], type=["pdf"])

docs, meta, vectorizer, doc_matrix = load_kb_and_vectorizer()

query = st.text_area(ui["query"], height=140)
top_k = st.slider("üìÑ Top Documents", 1, 5, 3)

if st.button(ui["button"]):
    if uploaded_pdf:
        context = read_uploaded_pdf(uploaded_pdf)
        pdf_sources = []
        st.info(ui["pdf_override"])
    else:
        context, pdf_sources = retrieve_context(
            query, vectorizer, doc_matrix, docs, meta, top_k
        )

    with st.spinner(ui["thinking"]):
        answer = ask_llm_cloud(query, context, selected_lang)

    st.subheader(ui["answer"])
    st.success(answer)

    if not uploaded_pdf:
        st.subheader(ui["pdf"])
        for s in pdf_sources:
            st.markdown(f"‚úÖ **{s['title']}**")
            st.markdown(f"[{ui['download']}]({s['url']})")

st.info(ui["info"])
