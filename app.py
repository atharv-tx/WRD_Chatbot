import streamlit as st
import json
import os
import requests

# SAFE PDF reader
try:
    import pdfplumber
except:
    pdfplumber = None

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# ---------------------------------------------------------
# üî• CHAT HISTORY MANAGEMENT
# ---------------------------------------------------------

def init_chat_history():
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []


def add_message(role, message):
    st.session_state.chat_history.append({
        "role": role,
        "message": message
    })


def get_history_for_llm():
    text = ""
    for msg in st.session_state.chat_history:
        speaker = "User" if msg["role"] == "user" else "Assistant"
        text += f"{speaker}: {msg['message']}\n"
    return text


def clear_history():
    st.session_state.chat_history = []


# ---------------------------------------------------------
# üåê LANGUAGE CONFIG (HINDI + ENGLISH + HINGLISH RESTORED)
# ---------------------------------------------------------

LANGUAGES = {
    "‡§π‡§ø‡§Ç‡§¶‡•Ä": {
        "title": "üíß ‡§ú‡§≤ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§µ‡§ø‡§≠‡§æ‡§ó ‡§õ‡§§‡•ç‡§§‡•Ä‡§∏‡§ó‡§¢‡§º ‚Äì ‡§è‡§Ü‡§à ‡§ö‡•à‡§ü‡§¨‡•â‡§ü",
        "desc": "‡§Ø‡§π ‡§ö‡•à‡§ü‡§¨‡•â‡§ü WRD ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º‡•ã‡§Ç ‡§î‡§∞ ‡§Ü‡§™‡§ï‡•á PDF ‡§∏‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§",
        "query": "‚úçÔ∏è ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≤‡§ø‡§ñ‡§ø‡§è",
        "button": "‚úÖ ‡§â‡§§‡•ç‡§§‡§∞ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç",
        "search": "üîé ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ñ‡•ã‡§ú‡•Ä ‡§ú‡§æ ‡§∞‡§π‡•Ä ‡§π‡•à...",
        "thinking": "ü§ñ ‡§â‡§§‡•ç‡§§‡§∞ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...",
        "answer": "ü§ñ ‡§ö‡•à‡§ü‡§¨‡•â‡§ü ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞:",
        "pdf": "üìÑ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§ø‡§è ‡§ó‡§è WRD PDF ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º:",
        "download": "‚¨áÔ∏è PDF ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "upload": "‚ûï ‡§Ö‡§™‡§®‡§æ PDF ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç (‡§µ‡•à‡§ï‡§≤‡•ç‡§™‡§ø‡§ï)",
        "pdf_override": "üìò ‡§â‡§§‡•ç‡§§‡§∞ ‡§Ü‡§™‡§ï‡•á ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§ø‡§è ‡§ó‡§è PDF ‡§™‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§π‡•à‡•§",
        "info": "‚ÑπÔ∏è ‡§Ø‡§π ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§ï‡•á‡§µ‡§≤ ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§® ‡§π‡•á‡§§‡•Å ‡§π‡•à‡•§"
    },

    "English": {
        "title": "üíß WRD Chhattisgarh ‚Äì AI Chatbot",
        "desc": "This chatbot answers using WRD data or your uploaded PDF.",
        "query": "‚úçÔ∏è Enter your question",
        "button": "‚úÖ Get Answer",
        "search": "üîé Searching...",
        "thinking": "ü§ñ Generating...",
        "answer": "ü§ñ Chatbot Answer:",
        "pdf": "üìÑ Used WRD PDFs:",
        "download": "‚¨áÔ∏è Download PDF",
        "upload": "‚ûï Upload PDF (optional)",
        "pdf_override": "üìò Answer based on your uploaded PDF.",
        "info": "‚ÑπÔ∏è This system is for guidance only."
    },

    "Hinglish": {
        "title": "üíß WRD Chhattisgarh ‚Äì AI Chatbot",
        "desc": "Ye chatbot WRD data aur aapke uploaded PDF se answer deta hai.",
        "query": "‚úçÔ∏è Apna sawaal likhiye",
        "button": "‚úÖ Answer Pao",
        "search": "üîé Documents dhoonde ja rahe hain...",
        "thinking": "ü§ñ Answer ban raha hai...",
        "answer": "ü§ñ Chatbot ka Answer:",
        "pdf": "üìÑ Use huye WRD PDF:",
        "download": "‚¨áÔ∏è PDF Download",
        "upload": "‚ûï Apna PDF Upload karein",
        "pdf_override": "üìò Answer sirf uploaded PDF se banaya gaya hai.",
        "info": "‚ÑπÔ∏è Ye system sirf guidance ke liye hai."
    }
}


# ---------------------------------------------------------
# üìö WRD Knowledge Base Loader
# ---------------------------------------------------------

@st.cache_resource
def load_kb_and_vectorizer():
    if not os.path.exists("wrd_kb.json"):
        st.error("‚ùå wrd_kb.json missing!")
        st.stop()

    with open("wrd_kb.json", "r", encoding="utf-8") as f:
        docs = json.load(f)

    texts, meta = [], []

    for d in docs:
        texts.append(f"{d.get('title', '')}\n\n{d.get('text', '')}")
        meta.append({
            "title": d.get("title", ""),
            "url": d.get("url", ""),
            "type": d.get("type", ""),
        })

    vectorizer = TfidfVectorizer()
    matrix = vectorizer.fit_transform(texts)

    return docs, meta, vectorizer, matrix


def retrieve_context(query, vectorizer, matrix, docs, meta, top_k=3):
    q_vec = vectorizer.transform([query])
    sims = cosine_similarity(q_vec, matrix)[0]
    idxs = sims.argsort()[::-1][:top_k]

    chunks = []
    pdf_sources = []

    for i in idxs:
        chunks.append(docs[i]["text"][:900])
        if meta[i]["type"].lower() == "pdf":
            pdf_sources.append(meta[i])

    return "\n\n----\n\n".join(chunks), pdf_sources


# ---------------------------------------------------------
# üìÑ PDF Reader
# ---------------------------------------------------------

def read_uploaded_pdf(uploaded):
    if pdfplumber is None:
        return "‚ùå PDF reader not supported."

    text = ""
    with pdfplumber.open(uploaded) as pdf:
        for page in pdf.pages:
            t = page.extract_text()
            if t:
                text += t + "\n"
    return text[:5000]


# ---------------------------------------------------------
# ü§ñ GROQ CLOUD LLM (WITH CHAT HISTORY)
# ---------------------------------------------------------

def ask_llm_cloud(query, context, history, selected_lang):

    if "GROQ_API_KEY" not in st.secrets:
        return "‚ùå GROQ_API_KEY missing in Streamlit Secrets!"

    key = st.secrets["GROQ_API_KEY"]

    prompt = f"""
You are an official WRD assistant.
Answer in this language: {selected_lang}
Use BOTH chat history and the WRD context.
Give a long, detailed, step-by-step answer.

Chat History:
{history}

Context:
{context}

User Question:
{query}
"""

    headers = {
        "Authorization": f"Bearer {key}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": "llama-3.1-8b-instant",
        "messages": [
            {"role": "system", "content": "You are a helpful WRD assistant."},
            {"role": "user", "content": prompt},
        ],
        "temperature": 0.2
    }

    res = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers=headers,
        json=payload,
        timeout=60
    )

    data = res.json()

    if "choices" not in data:
        return f"‚ùå Groq Error: {data}"

    return data["choices"][0]["message"]["content"]


# ---------------------------------------------------------
# üé® UI (No Changes ‚Äî Same As Your Original)
# ---------------------------------------------------------

st.set_page_config(page_title="WRD AI Chatbot", layout="centered")
init_chat_history()

selected_lang = st.selectbox("üåê Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç", list(LANGUAGES.keys()))
ui = LANGUAGES[selected_lang]

st.title(ui["title"])
st.markdown(ui["desc"])

uploaded_pdf = st.file_uploader(ui["upload"], type=["pdf"])

docs, meta, vectorizer, matrix = load_kb_and_vectorizer()

query = st.text_area(ui["query"], height=140)
top_k = st.slider("üìÑ Top Documents", 1, 5, 3)

pdf_sources = []  # prevent undefined error

if st.button(ui["button"]):

    history = get_history_for_llm()

    if uploaded_pdf:
        context = read_uploaded_pdf(uploaded_pdf)
        pdf_sources = []
        st.info(ui["pdf_override"])

    else:
        context, pdf_sources = retrieve_context(
            query, vectorizer, matrix, docs, meta, top_k
        )

    with st.spinner(ui["thinking"]):
        answer = ask_llm_cloud(query, context, history, selected_lang)

    add_message("user", query)
    add_message("assistant", answer)

# ---------------------------------------------------------
# üí¨ Show Chat History
# ---------------------------------------------------------

st.subheader(ui["answer"])

for msg in st.session_state.chat_history:
    if msg["role"] == "user":
        st.markdown(f"**üßë User:** {msg['message']}")
    else:
        st.markdown(f"**ü§ñ Bot:** {msg['message']}")

# ---------------------------------------------------------
# PDF Info
# ---------------------------------------------------------

if pdf_sources:
    st.subheader(ui["pdf"])
    for p in pdf_sources:
        st.markdown(f"üìÑ **{p['title']}**")
        st.markdown(f"[{ui['download']}]({p['url']})")

# ---------------------------------------------------------
# Clear Chat Button
# ---------------------------------------------------------

if st.button("üóë Clear Chat"):
    clear_history()
    st.success("Chat cleared!")

st.info(ui["info"])
