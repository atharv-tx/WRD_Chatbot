import streamlit as st
import json
import os
import requests
import re

# SAFE PDF reader
try:
    import pdfplumber
except:
    pdfplumber = None

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity



# ============================================================
# üß† CHAT HISTORY + PDF SOURCE MEMORY
# ============================================================

def init_chat_history():
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    if "last_pdf_sources" not in st.session_state:
        st.session_state.last_pdf_sources = []

    if "meta_mode" not in st.session_state:
        st.session_state.meta_mode = False


def add_message(role, message):
    st.session_state.chat_history.append({"role": role, "message": message})


def get_history_for_llm():
    # Only last 6 messages ‚Üí improves quality
    text = ""
    for m in st.session_state.chat_history[-6:]:
        speaker = "User" if m["role"] == "user" else "Assistant"
        text += f"{speaker}: {m['message']}\n"
    return text


def clear_history():
    st.session_state.chat_history = []
    st.session_state.last_pdf_sources = []
    st.session_state.meta_mode = False



# ============================================================
# üåê LANGUAGES
# ============================================================

LANGUAGES = {
    "‡§π‡§ø‡§Ç‡§¶‡•Ä": {
        "meta": "‡§Ø‡§π ‡§ö‡•à‡§ü‡§¨‡•â‡§ü WRD ‡§ï‡•á ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•ç‡§ï‡•à‡§® ‡§ï‡§∞‡§ï‡•á RAG ‡§§‡§ï‡§®‡•Ä‡§ï ‡§∏‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§",
        "title": "‡§ú‡§≤ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§µ‡§ø‡§≠‡§æ‡§ó AI Chatbot",
        "desc": "‡§Ø‡§π ‡§ö‡•à‡§ü‡§¨‡•â‡§ü WRD ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º‡•ã‡§Ç ‡§î‡§∞ ‡§Ü‡§™‡§ï‡•á PDF ‡§∏‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§",
        "query": "‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≤‡§ø‡§ñ‡§ø‡§è",
        "button": "‡§â‡§§‡•ç‡§§‡§∞ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç",
        "thinking": "‡§â‡§§‡•ç‡§§‡§∞ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...",
        "answer": "‡§ö‡•à‡§ü‡§¨‡•â‡§ü ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞:",
        "pdf": "‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§ø‡§è ‡§ó‡§è WRD PDF:",
        "download": "PDF ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "upload": "PDF ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "pdf_override": "‡§â‡§§‡•ç‡§§‡§∞ ‡§Ü‡§™‡§ï‡•á ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§ø‡§è ‡§ó‡§è PDF ‡§™‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§π‡•à‡•§",
        "info": "‡§Ø‡§π ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§ï‡•á‡§µ‡§≤ ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§® ‡§π‡•á‡§§‡•Å ‡§π‡•à‡•§",
    },

    "English": {
        "meta": "This chatbot uses WRD documents & RAG (Retrieval-Augmented Generation) to provide official information.",
        "title": "WRD Chhattisgarh ‚Äì AI Chatbot",
        "desc": "This chatbot answers using WRD data or your PDF.",
        "query": "Ask your question",
        "button": "Get Answer",
        "thinking": "Generating answer...",
        "answer": "Chatbot Answer:",
        "pdf": "Used WRD PDFs:",
        "download": "Download PDF",
        "upload": "Upload PDF",
        "pdf_override": "Answer based on your uploaded PDF.",
        "info": "This system is for guidance only.",
    },

    "Hinglish": {
        "meta": "Yeh chatbot WRD documents ko RAG ke through analyze karke exact info deta hai.",
        "title": "WRD Chhattisgarh ‚Äì AI Chatbot",
        "desc": "Ye chatbot WRD ya uploaded PDF se answer deta hai.",
        "query": "Apna sawaal likhiye",
        "button": "Answer Pao",
        "thinking": "Answer tayyar ho raha hai...",
        "answer": "Chatbot Ka Answer:",
        "pdf": "Use huye WRD PDF:",
        "download": "PDF Download",
        "upload": "PDF Upload Karein",
        "pdf_override": "Answer uploaded PDF se liya gaya hai.",
        "info": "Ye system sirf guidance ke liye hai.",
    }
}



# ============================================================
# ü§ñ META-QUESTION + PDF-CHECK DETECTION
# ============================================================

META_QUESTIONS = [
    r"what is this chatbot",
    r"what can you do",
    r"who are you",
    r"your purpose",
    r"kaise kaam",
    r"tum kya",
    r"bot kya",
    r"chatbot",
    r"how .* work",
]

META_FOLLOWUP = [
    r"more detail",
    r"detail",
    r"explain",
    r"continue",
    r"aur",
]


WRD_KEYWORDS = [
    "irrigation", "water", "borewell", "dam", "pipeline",
    "canal", "scheme", "wrd", "chhattisgarh", "ground water",
    "act", "permission"
]


# PDF Query detection
PDF_QUERY_PATTERNS = [
    r"which pdf",
    r"list pdf",
    r"which document",
    r"source pdf",
    r"pdf used",
    r"kis pdf",
]

def is_pdf_request(q):
    q = q.lower()
    return any(re.search(p, q) for p in PDF_QUERY_PATTERNS)


def is_meta_question(q):
    q = q.lower()

    # If WRD keywords found ‚Üí NOT meta
    if any(w in q for w in WRD_KEYWORDS):
        return False

    # If already in meta mode ‚Üí follow-up continuation
    if st.session_state.meta_mode:
        if any(re.search(p, q) for p in META_FOLLOWUP):
            return True

    # Fresh meta-question
    return any(re.search(p, q) for p in META_QUESTIONS)



# ============================================================
# üìö LOAD KNOWLEDGE BASE
# ============================================================

@st.cache_resource
def load_kb_and_vectorizer():
    with open("wrd_kb.json", "r", encoding="utf-8") as f:
        docs = json.load(f)

    texts = [f"{d['title']}\n\n{d['text']}" for d in docs]
    meta = [{"title": d["title"], "url": d["url"], "type": d["type"]} for d in docs]

    vec = TfidfVectorizer()
    matrix = vec.fit_transform(texts)

    return docs, meta, vec, matrix


def retrieve_context(query, vectorizer, matrix, docs, meta, top_k):
    q_vec = vectorizer.transform([query])
    sims = cosine_similarity(q_vec, matrix)[0]
    idxs = sims.argsort()[::-1][:top_k]

    chunks, pdf_list = [], []

    for i in idxs:
        chunks.append(docs[i]["text"][:900])
        if meta[i]["type"] == "pdf":
            pdf_list.append(meta[i])

    return "\n\n----\n\n".join(chunks), pdf_list



# ============================================================
# ü§ñ GROQ LLM CALL
# ============================================================

def ask_llm_cloud(query, context, history, lang):
    key = st.secrets["GROQ_API_KEY"]

    final_prompt = f"""
You are WRD Assistant.

RULES:
- For WRD factual questions ‚Üí use ONLY the context below.
- Chat history is ONLY for tone continuity, NOT facts.
- Give long, accurate, step-by-step answers.

Chat History:
{history}

RAG Context:
{context}

User Question:
{query}
"""

    payload = {
        "model": "llama-3.1-8b-instant",
        "messages": [
            {"role": "system", "content": "You are WRD expert assistant."},
            {"role": "user", "content": final_prompt},
        ],
        "temperature": 0.15
    }

    res = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers={"Authorization": f"Bearer {key}"},
        json=payload
    )

    data = res.json()
    return data["choices"][0]["message"]["content"]



# ============================================================
# üü¶ UI (unchanged)
# ============================================================

st.set_page_config(page_title="WRD AI Chatbot", layout="centered")
init_chat_history()

lang = st.selectbox("Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç", list(LANGUAGES.keys()))
ui = LANGUAGES[lang]

st.title(ui["title"])
st.markdown(ui["desc"])

uploaded_pdf = st.file_uploader(ui["upload"], type=["pdf"])

docs, meta, vectorizer, matrix = load_kb_and_vectorizer()

query = st.text_area(ui["query"])
top_k = st.slider("Top Documents", 1, 5, 3)

pdf_sources = []



# ============================================================
# üöÄ MAIN BUTTON LOGIC
# ============================================================

if st.button(ui["button"]):

    user_q = query.strip()
    history = get_history_for_llm()

    # 1Ô∏è‚É£ If user asks "WHICH PDF DID YOU USE?"
    if is_pdf_request(user_q):
        if st.session_state.last_pdf_sources:
            ans = "üìÑ PDFs used in last answer:\n\n"
            for p in st.session_state.last_pdf_sources:
                ans += f"- **{p['title']}** ‚Üí {p['url']}\n"
        else:
            ans = "‚ùó No PDF was used for the previous answer."

        add_message("user", user_q)
        add_message("assistant", ans)
        st.stop()

    # 2Ô∏è‚É£ META question?
    if is_meta_question(user_q):
        st.session_state.meta_mode = True
        ans = ui["meta"]
        add_message("user", user_q)
        add_message("assistant", ans)
        st.stop()

    # Normal WRD question ‚Üí turn meta_mode off
    st.session_state.meta_mode = False

    # 3Ô∏è‚É£ Handle PDF override
    if uploaded_pdf:
        context = pdfplumber.open(uploaded_pdf).pages[0].extract_text()[:5000]
        pdf_sources = []
        st.info(ui["pdf_override"])

    else:
        context, pdf_sources = retrieve_context(
            user_q, vectorizer, matrix, docs, meta, top_k
        )

    with st.spinner(ui["thinking"]):
        ans = ask_llm_cloud(user_q, context, history, lang)

    # Save which PDFs were used
    st.session_state.last_pdf_sources = pdf_sources

    add_message("user", user_q)
    add_message("assistant", ans)



# ============================================================
# üí¨ CHAT HISTORY
# ============================================================

st.subheader(ui["answer"])
for m in st.session_state.chat_history:
    speaker = "üßë" if m["role"] == "user" else "ü§ñ"
    st.markdown(f"**{speaker} {m['message']}**")



# ============================================================
# üìÑ PDF Sources (for WRD)
# ============================================================

if st.session_state.last_pdf_sources:
    st.subheader(ui["pdf"])
    for p in st.session_state.last_pdf_sources:
        st.markdown(f"üìÑ **{p['title']}** ‚Äî [{ui['download']}]({p['url']})")



# ============================================================
# CLEAR CHAT
# ============================================================

if st.button("üóë Clear Chat"):
    clear_history()
    st.success("Chat Cleared!")

st.info(ui["info"])
