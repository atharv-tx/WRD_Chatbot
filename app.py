import streamlit as st
import json
import os
import requests

# ‚úÖ SAFE pdfplumber fallback
try:
    import pdfplumber
except:
    pdfplumber = None

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# -------------------------
# üåê LANGUAGE CONFIG
# -------------------------

LANGUAGES = {
    "‡§π‡§ø‡§Ç‡§¶‡•Ä": {
        "title": "üíß ‡§ú‡§≤ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§µ‡§ø‡§≠‡§æ‡§ó ‡§õ‡§§‡•ç‡§§‡•Ä‡§∏‡§ó‡§¢‡§º ‚Äì ‡§è‡§Ü‡§à ‡§ö‡•à‡§ü‡§¨‡•â‡§ü",
        "desc": "‡§Ø‡§π ‡§ö‡•à‡§ü‡§¨‡•â‡§ü WRD ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º‡•ã‡§Ç ‡§î‡§∞ ‡§Ü‡§™‡§ï‡•á PDF ‡§∏‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§",
        "query": "‚úçÔ∏è ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≤‡§ø‡§ñ‡§ø‡§è",
        "button": "‚úÖ ‡§â‡§§‡•ç‡§§‡§∞ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç",
        "search": "üîé ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ñ‡•ã‡§ú‡•Ä ‡§ú‡§æ ‡§∞‡§π‡•Ä ‡§π‡•à...",
        "thinking": "ü§ñ ‡§â‡§§‡•ç‡§§‡§∞ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...",
        "answer": "ü§ñ ‡§ö‡•à‡§ü‡§¨‡•â‡§ü ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞:",
        "pdf": "üìÑ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§ø‡§è ‡§ó‡§è WRD PDF ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º:",
        "download": "‚¨áÔ∏è PDF ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "upload": "‚ûï ‡§Ö‡§™‡§®‡§æ PDF ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç (‡§µ‡•à‡§ï‡§≤‡•ç‡§™‡§ø‡§ï)",
        "pdf_override": "‚úÖ ‡§â‡§§‡•ç‡§§‡§∞ ‡§Ü‡§™‡§ï‡•á ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§ø‡§è ‡§ó‡§è PDF ‡§∏‡•á ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§",
        "info": "‚ÑπÔ∏è ‡§Ø‡§π ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§ï‡•á‡§µ‡§≤ ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§® ‡§π‡•á‡§§‡•Å ‡§π‡•à‡•§"
    },
    "English": {
        "title": "üíß WRD Chhattisgarh ‚Äì AI Chatbot",
        "desc": "This chatbot answers using WRD data or your uploaded PDF.",
        "query": "‚úçÔ∏è Enter your question",
        "button": "‚úÖ Get Answer",
        "search": "üîé Searching documents...",
        "thinking": "ü§ñ Generating answer...",
        "answer": "ü§ñ Chatbot Answer:",
        "pdf": "üìÑ Used WRD PDF Documents:",
        "download": "‚¨áÔ∏è Download PDF",
        "upload": "‚ûï Upload your PDF (optional)",
        "pdf_override": "‚úÖ Answer generated from your uploaded PDF.",
        "info": "‚ÑπÔ∏è This system is for guidance only."
    },
    "Hinglish": {
        "title": "üíß WRD Chhattisgarh ‚Äì AI Chatbot",
        "desc": "Ye chatbot WRD aur uploaded PDF se answer deta hai.",
        "query": "‚úçÔ∏è Apna sawaal likhiye",
        "button": "‚úÖ Answer Pao",
        "search": "üîé Documents search ho rahe hain...",
        "thinking": "ü§ñ Answer banaya ja raha hai...",
        "answer": "ü§ñ Chatbot ka Answer:",
        "pdf": "üìÑ Use hue WRD PDF:",
        "download": "‚¨áÔ∏è PDF Download",
        "upload": "‚ûï Apna PDF Upload Karein",
        "pdf_override": "‚úÖ Answer sirf uploaded PDF se diya gaya hai.",
        "info": "‚ÑπÔ∏è Ye system sirf guidance ke liye hai."
    }
}

# -------------------------
# 1. Load WRD Knowledge Base
# -------------------------

@st.cache_resource
def load_kb_and_vectorizer():
    if not os.path.exists("wrd_kb.json"):
        st.error("‚ùå wrd_kb.json ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§")
        st.stop()

    with open("wrd_kb.json", "r", encoding="utf-8") as f:
        docs = json.load(f)

    texts = []
    meta = []

    for d in docs:
        combined = f"{d.get('title', '')}\n\n{d.get('text', '')}"
        texts.append(combined)
        meta.append({
            "title": d.get("title", ""),
            "url": d.get("url", ""),
            "type": d.get("type", "")
        })

    vectorizer = TfidfVectorizer()
    doc_matrix = vectorizer.fit_transform(texts)

    return docs, meta, vectorizer, doc_matrix


def retrieve_context(query, vectorizer, doc_matrix, docs, meta, top_k=3):
    query_vec = vectorizer.transform([query])
    sims = cosine_similarity(query_vec, doc_matrix)[0]
    top_idx = sims.argsort()[::-1][:top_k]

    chunks = []
    pdf_sources = []

    for idx in top_idx:
        chunks.append(docs[idx]["text"][:900])
        if meta[idx]["type"].lower() == "pdf":
            pdf_sources.append(meta[idx])

    return "\n\n----\n\n".join(chunks), pdf_sources


# -------------------------
# 2. PDF READER
# -------------------------

def read_uploaded_pdf(uploaded_file):
    if pdfplumber is None:
        return "‚ùå PDF reader supported ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§"

    text = ""
    with pdfplumber.open(uploaded_file) as pdf:
        for page in pdf.pages:
            t = page.extract_text()
            if t:
                text += t + "\n"

    return text[:4000]


# -------------------------
# 3. GROQ CLOUD LLM (ONLY)
# -------------------------

def ask_llm_cloud(query, context, selected_lang):
    try:
        if "GROQ_API_KEY" not in st.secrets:
            return "‚ùå GROQ_API_KEY Streamlit Secrets ‡§Æ‡•á‡§Ç ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§"

        GROQ_API_KEY = st.secrets["GROQ_API_KEY"]

        prompt = f"""
You are an official WRD information assistant.
Answer strictly in this language: {selected_lang}.
Use ONLY the given context.
Provide a long, detailed, step-by-step answer.

Context:
{context}

Question:
{query}
"""

        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": "llama-3.1-8b-instant",
            "messages": [
                {"role": "system", "content": "You are a helpful WRD assistant."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.2
        }

        response = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=60
        )

        data = response.json()

        if response.status_code != 200:
            return f"‚ùå Groq API Error {response.status_code}: {data}"

        if "choices" not in data:
            return f"‚ùå Invalid Groq Response: {data}"

        return data["choices"][0]["message"]["content"]

    except Exception as e:
        return f"‚ùå Network Error: {str(e)}"


# -------------------------
# 4. STREAMLIT UI
# -------------------------

st.set_page_config(page_title="WRD AI Chatbot", layout="centered")

selected_lang = st.selectbox("üåê Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç", list(LANGUAGES.keys()))
ui = LANGUAGES[selected_lang]

st.title(ui["title"])
st.markdown(ui["desc"])

uploaded_pdf = st.file_uploader(ui["upload"], type=["pdf"])

docs, meta, vectorizer, doc_matrix = load_kb_and_vectorizer()

query = st.text_area(ui["query"], height=140)
top_k = st.slider("üìÑ Top Documents", 1, 5, 3)

if st.button(ui["button"]):
    if not query.strip():
        st.warning("‚ùó ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§≤‡§ø‡§ñ‡•á‡§Ç‡•§")
    else:
        if uploaded_pdf:
            context = read_uploaded_pdf(uploaded_pdf)
            pdf_sources = []
            st.info(ui["pdf_override"])
        else:
            context, pdf_sources = retrieve_context(
                query, vectorizer, doc_matrix, docs, meta, top_k
            )

        with st.spinner(ui["thinking"]):
            answer = ask_llm_cloud(query, context, selected_lang)

        st.subheader(ui["answer"])
        st.success(answer)

        if not uploaded_pdf:
            st.subheader(ui["pdf"])
            for s in pdf_sources:
                st.markdown(f"üìÑ **{s['title']}**")
                st.markdown(f"[{ui['download']}]({s['url']})")

st.info(ui["info"])
