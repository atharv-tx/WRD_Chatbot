import streamlit as st
import json
import os
import requests
import pdfplumber
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# -------------------------
# ЁЯМР LANGUAGE CONFIG
# -------------------------

LANGUAGES = {
    "рд╣рд┐рдВрджреА": {
        "title": "ЁЯТз рдЬрд▓ рд╕рдВрд╕рд╛рдзрди рд╡рд┐рднрд╛рдЧ рдЫрддреНрддреАрд╕рдЧрдврд╝ тАУ рдПрдЖрдИ рдЪреИрдЯрдмреЙрдЯ",
        "desc": "рдпрд╣ рдЪреИрдЯрдмреЙрдЯ WRD рдХреЗ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдФрд░ рдЖрдкрдХреЗ рдЕрдкрд▓реЛрдб рдХрд┐рдП рдЧрдП PDF рд╕реЗ рдЙрддреНрддрд░ рджреЗрддрд╛ рд╣реИред",
        "query": "тЬНя╕П рдЕрдкрдирд╛ рд╕рд╡рд╛рд▓ рд▓рд┐рдЦрд┐рдП",
        "button": "тЬЕ рдЙрддреНрддрд░ рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВ",
        "search": "ЁЯФО рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рд╕реЗ рдЬрд╛рдирдХрд╛рд░реА рдЦреЛрдЬреА рдЬрд╛ рд░рд╣реА рд╣реИ...",
        "thinking": "ЁЯдЦ рдЙрддреНрддрд░ рддреИрдпрд╛рд░ рдХрд┐рдпрд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИ...",
        "answer": "ЁЯдЦ рдЪреИрдЯрдмреЙрдЯ рдХрд╛ рдЙрддреНрддрд░:",
        "pdf": "ЁЯУД рдЙрдкрдпреЛрдЧ рдХрд┐рдП рдЧрдП WRD PDF рджрд╕реНрддрд╛рд╡реЗрдЬрд╝:",
        "download": "тмЗя╕П PDF рдбрд╛рдЙрдирд▓реЛрдб рдХрд░реЗрдВ",
        "upload": "тЮХ рдЕрдкрдирд╛ PDF рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ (рдЕрдЧрд░ рдЖрдк WRD рдХреЗ рдЕрд▓рд╛рд╡рд╛ рдЙрд╕реА PDF рд╕реЗ рдЙрддреНрддрд░ рдЪрд╛рд╣рддреЗ рд╣реИрдВ)",
        "pdf_override": "тЬЕ рдЙрддреНрддрд░ рдХреЗрд╡рд▓ рдЖрдкрдХреЗ рдЕрдкрд▓реЛрдб рдХрд┐рдП рдЧрдП PDF рд╕реЗ рддреИрдпрд╛рд░ рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИред",
        "info": "тД╣я╕П рдпрд╣ рдкреНрд░рдгрд╛рд▓реА рдХреЗрд╡рд▓ рдорд╛рд░реНрдЧрджрд░реНрд╢рди рд╣реЗрддреБ рд╣реИред"
    },
    "English": {
        "title": "ЁЯТз WRD Chhattisgarh тАУ AI Chatbot",
        "desc": "This chatbot answers using official WRD documents and your uploaded PDF.",
        "query": "тЬНя╕П Enter your question",
        "button": "тЬЕ Get Answer",
        "search": "ЁЯФО Searching documents...",
        "thinking": "ЁЯдЦ Generating answer...",
        "answer": "ЁЯдЦ Chatbot Answer:",
        "pdf": "ЁЯУД Used WRD PDF Documents:",
        "download": "тмЗя╕П Download PDF",
        "upload": "тЮХ Upload your own PDF (to override WRD data)",
        "pdf_override": "тЬЕ Answer is generated ONLY from your uploaded PDF.",
        "info": "тД╣я╕П This system is for guidance only."
    },
    "Hinglish": {
        "title": "ЁЯТз WRD Chhattisgarh тАУ AI Chatbot",
        "desc": "Ye chatbot WRD ke documents aur aapke upload PDF se answer deta hai.",
        "query": "тЬНя╕П Apna sawaal likhiye",
        "button": "тЬЕ Answer Pao",
        "search": "ЁЯФО Documents se info dhoondi ja rahi hai...",
        "thinking": "ЁЯдЦ Answer banaya ja raha hai...",
        "answer": "ЁЯдЦ Chatbot Ka Answer:",
        "pdf": "ЁЯУД Use hue WRD PDF Documents:",
        "download": "тмЗя╕П PDF Download Karein",
        "upload": "тЮХ Apna PDF upload karein (WRD ko ignore karne ke liye)",
        "pdf_override": "тЬЕ Answer sirf aapke uploaded PDF se banaya gaya hai.",
        "info": "тД╣я╕П Ye system sirf guidance ke liye hai."
    }
}


# -------------------------
# 1. Load WRD Knowledge Base
# -------------------------

@st.cache_resource
def load_kb_and_vectorizer():
    if not os.path.exists("wrd_kb.json"):
        raise FileNotFoundError("тЭМ wrd_kb.json рдирд╣реАрдВ рдорд┐рд▓рд╛ред рдкрд╣рд▓реЗ fetch_wrd_data.py рдЪрд▓рд╛рдПрдБред")

    with open("wrd_kb.json", "r", encoding="utf-8") as f:
        docs = json.load(f)

    texts = []
    meta = []

    for d in docs:
        combined = f"{d.get('title', '')}\n\n{d.get('text', '')}"
        texts.append(combined)
        meta.append({
            "title": d.get("title", ""),
            "url": d.get("url", ""),
            "type": d.get("type", "")
        })

    vectorizer = TfidfVectorizer()
    doc_matrix = vectorizer.fit_transform(texts)

    return docs, meta, vectorizer, doc_matrix


def retrieve_context(query, vectorizer, doc_matrix, docs, meta, top_k=3):
    query_vec = vectorizer.transform([query])
    sims = cosine_similarity(query_vec, doc_matrix)[0]
    top_idx = sims.argsort()[::-1][:top_k]

    chunks = []
    pdf_sources = []

    for idx in top_idx:
        d = docs[idx]
        chunks.append(d["text"][:800])

        if meta[idx]["type"].lower() == "pdf":
            pdf_sources.append(meta[idx])

    return "\n\n----\n\n".join(chunks), pdf_sources


# -------------------------
# 2. USER UPLOADED PDF READER
# -------------------------

def read_uploaded_pdf(uploaded_file):
    full_text = ""
    with pdfplumber.open(uploaded_file) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if text:
                full_text += text + "\n"
    return full_text[:3500]   # тЬЕ safe limit for speed


# -------------------------
# 3. Ollama (AUTO CONTINUE)
# -------------------------

def ask_llm_ollama(query, context, selected_lang):
    system_prompt = f"""
You are a WRD Chhattisgarh assistant.
Give answer ONLY in this language: {selected_lang}.
Use ONLY the given context.
If info is not present, clearly say it is unavailable.
"""

    def generate_once(prompt):
        resp = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "llama3.1",
                "prompt": prompt,
                "stream": True,
                "options": {
                    "num_predict": 700,
                    "temperature": 0.15,
                    "top_p": 0.95 
                },
            },
            timeout=120,
            stream=True
        )

        final_text = ""
        for line in resp.iter_lines(decode_unicode=True):
            if line:
                data = json.loads(line)
                if "response" in data:
                    final_text += data["response"]
                if data.get("done"):
                    break
        return final_text.strip()

    full_prompt = f"""
{system_prompt}

Context:
{context}

Question:
{query}
"""

    answer = generate_once(full_prompt)

    # тЬЕ Auto-continue if short or cut
    if len(answer) < 350:
        continuation = generate_once("Continue the same answer clearly:")
        answer += "\n" + continuation

    return answer.strip()


# -------------------------
# 4. Streamlit UI
# -------------------------

st.set_page_config(page_title="WRD AI Chatbot", layout="centered")

selected_lang = st.selectbox("ЁЯМР Select Language / рднрд╛рд╖рд╛ рдЪреБрдиреЗрдВ", list(LANGUAGES.keys()))
ui = LANGUAGES[selected_lang]

st.title(ui["title"])
st.markdown(ui["desc"])

# тЬЕ PDF Upload Section (STRICT OVERRIDE)
uploaded_pdf = st.file_uploader(ui["upload"], type=["pdf"])

try:
    docs, meta, vectorizer, doc_matrix = load_kb_and_vectorizer()
except Exception as e:
    st.error(str(e))
    st.stop()

query = st.text_area(ui["query"], height=120)
top_k = st.slider("ЁЯУД Top Documents", 1, 5, 3)

if st.button(ui["button"]):
    if not query.strip():
        st.warning("Please enter a question.")
    else:
        with st.spinner(ui["search"]):

            # тЬЕтЬЕтЬЕ STRICT OVERRIDE MODE
            if uploaded_pdf is not None:
                context = read_uploaded_pdf(uploaded_pdf)
                pdf_sources = []   # WRD PDFs рдкреВрд░реА рддрд░рд╣ ignore
                st.info(ui["pdf_override"])
            else:
                context, pdf_sources = retrieve_context(
                    query, vectorizer, doc_matrix, docs, meta, top_k
                )

        with st.spinner(ui["thinking"]):
            answer = ask_llm_ollama(query, context, selected_lang)

        st.subheader(ui["answer"])
        st.success(answer)

        # тЬЕ тЬЕ тЬЕ ONLY WRD PDFs + DOWNLOAD BUTTON (рдЬрдм upload рдирд╣реАрдВ рдХрд┐рдпрд╛ рд╣реЛ)
        if uploaded_pdf is None:
            st.subheader(ui["pdf"])
            if pdf_sources:
                for s in pdf_sources:
                    st.markdown(f"тЬЕ **{s['title']}**")
                    st.markdown(f"ЁЯФЧ {s['url']}")
                    st.markdown(f"[{ui['download']}]({s['url']})")
                    st.markdown("---")
            else:
                st.info("рдЗрд╕ рдЙрддреНрддрд░ рдХреЗ рд▓рд┐рдП рдХреЛрдИ WRD PDF рдЙрдкрдпреЛрдЧ рдореЗрдВ рдирд╣реАрдВ рд▓рд┐рдпрд╛ рдЧрдпрд╛ред")

st.info(ui["info"])
